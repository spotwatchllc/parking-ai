general:
  project_name: COCO_2017_person_Demo
  model_type: st_yolo_lc_v1
#choices=[st_ssd_mobilenet_v1, ssd_mobilenet_v2_fpnlite, tiny_yolo_v2, st_yolo_lc_v1, 
#         st_yolo_x, yolo_v8, yolo_v5u]
  model_path: 
  logs_dir: logs
  saved_models_dir: saved_models
  gpu_memory_limit: 16
  num_threads_tflite: 4
  global_seed: 127

operation_mode: chain_tqeb
#choices=['training' , 'evaluation', 'deployment', 'quantization', 'benchmarking',
#        'chain_tqeb','chain_tqe','chain_eqe','chain_qb','chain_eqeb','chain_qd ']

dataset:
  name: COCO_2017_person
  class_names: [ person ]
  training_path: /dataset/coco_person_2017_tfs/train
  validation_path:
  validation_split: 0.1
  test_path: /dataset/coco_person_2017_tfs/val
  quantization_path: /dataset/coco_person_2017_tfs/val
  quantization_split: 0.01

preprocessing:
  rescaling: { scale: 1/127.5, offset: -1 }
  resizing:
    aspect_ratio: fit
    interpolation: nearest
  color_mode: rgb
                       
data_augmentation:
  ########## For tiny_yolo_v2 and st_yolo_lc_v1 only ###########
  random_periodic_resizing:
    period: 10
    image_sizes: [(192, 192), (224, 224), (256, 256), (288, 288), (320, 320), (352, 352),
                  (384, 384), (416, 416), (448, 448), (480, 480), (512, 512),
                  (544, 544), (576, 576), (608, 608)]
  random_flip:
    mode: horizontal
  random_crop:
    crop_center_x: (0.25, 0.75)
    crop_center_y: (0.25, 0.75)
    crop_width: (0.5, 0.9)
    crop_height: (0.5, 0.9)
    change_rate: 0.9
  random_contrast:
    factor: 0.4
  random_brightness:
    factor: 0.3 

training:
  model:
    # alpha: 0.35
    input_shape: (192, 192, 3)
    # pretrained_weights: imagenet
  dropout:
  batch_size: 64
  epochs: 4
  optimizer:
    Adam:
      learning_rate: 0.005
  callbacks:
    ReduceLROnPlateau:
      monitor: val_map
      patience: 10
      factor: 0.25
    ModelCheckpoint:
      monitor: val_map
    EarlyStopping:
      monitor: val_map
      patience: 20

postprocessing:
  confidence_thresh: 0.001
  NMS_thresh: 0.5
  IoU_eval_thresh: 0.4
  plot_metrics: False   # Plot precision versus recall curves. Default is False.
  max_detection_boxes: 100

quantization:
  quantizer: TFlite_converter
  quantization_type: PTQ
  quantization_input_type: uint8
  quantization_output_type: float
  granularity: per_channel   #per_tensor
  optimize: False   #can be True if per_tensor
  export_dir: quantized_models

benchmarking:
  board: STM32H747I-DISCO

tools:
  stedgeai:
    version: 10.0.0
    optimization: balanced
    on_cloud: True
    path_to_stedgeai: C:/Users/<XXXXX>/STM32Cube/Repository/Packs/STMicroelectronics/X-CUBE-AI/<*.*.*>/Utilities/windows/stedgeai.exe
  path_to_cubeIDE: C:/ST/STM32CubeIDE_<*.*.*>/STM32CubeIDE/stm32cubeide.exe

deployment:
  c_project_path: ../../application_code/object_detection/STM32H7/
  IDE: GCC
  verbosity: 1
  hardware_setup:
    serie: STM32H7
    board: STM32H747I-DISCO

mlflow:
  uri: ./experiments_outputs/mlruns

hydra:
  run:
    dir: ./experiments_outputs/${now:%Y_%m_%d_%H_%M_%S}
    